{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0191d78d",
   "metadata": {},
   "source": [
    "# Challenge - Football match prediction\n",
    "\n",
    "## Description\n",
    "\n",
    "For this week's challenge, we will try to build a model for the football match outcome prediction. The data containing the international football match results from 1872 to 2021 can be found in the Kaggle (***see Kaggle section for link***). \n",
    "\n",
    "On the other hand, this week's challenge has been created in the format of Kaggle in-class competition: we will develop our model on the given ```train``` dataset and will have to submit a file containing predictions from the ```test``` dataset. Then, according to the accuracy of your prediction, you will be ranked in the leaderboard.\n",
    "\n",
    "\n",
    "## Kaggle\n",
    "\n",
    "You can access the competition via [this link](https://www.kaggle.com/c/ucl-ai-society-football-match-prediction/data) where you can also find the detailed description of the challenge and provided data. The key points:\n",
    "\n",
    "- The data section contains 3 files - ```train.csv```, ```test.csv```, ```sample_submission.csv```. You should develop the model using the **```train.csv```** file.\n",
    "- As the outcome is binary, we are going to use the logistic regression model.\n",
    "- After training the model, use it to predict the outcomes of the ```test.csv``` dataset. With outputs and id, create a submission file (the format can be seen in the ```sample_submission.csv``` file).\n",
    "- As the dataset features are in string format, we are going to use the string-to-integer encoder. Since it will only be covered in the latter tutorials, at this point, we will provide the function that takes the feature and provides transformed output.\n",
    "\n",
    "![photo](https://user-images.githubusercontent.com/73468790/137705753-f5bd879d-0a60-4bce-bf3c-63a9b38ae5c0.jpg)\n",
    "\n",
    "## Code\n",
    "\n",
    "You can use the code structure below as a guidance. Some of the steps will be already done for you (string to integer encoding), so **do not change it**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56834b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b5851",
   "metadata": {},
   "source": [
    "After importing the libraries, specify the path for the downloaded ```train.csv``` dataset and read the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85469153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "PATH = \n",
    "data = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94260a0b",
   "metadata": {},
   "source": [
    "As usual, feel free to have a look at data using an appropriate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70a4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the top dataset values with the Pandas function (.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb37b8",
   "metadata": {},
   "source": [
    "During the previous time, we learned the importance of checking missing values. Check if there are any missing values and if so, remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d829ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check missing values and remove them (if there are any)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3995b8",
   "metadata": {},
   "source": [
    "Now we came to the data preprocessing step. As you can see, we have already written the ```encode()``` function which takes the data file and outputs ```X``` features. **Do not change this part of the code**.\n",
    "\n",
    "You will have to write a function that:\n",
    "- Takes the data file and passes it through the ```encode()``` function\n",
    "- Drops the unwanted columns from the data file\n",
    "- Extracts the outcome from the data file and converts it to numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18415fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(data):\n",
    "    \n",
    "    #--------------------------------------\n",
    "    #Extracting teams' names\n",
    "    H_team = np.array(data['home_team'])\n",
    "    A_team = np.array(data['away_team'])\n",
    "    \n",
    "    Teams = np.hstack((H_team, A_team))\n",
    "    \n",
    "    #--------------------------------------\n",
    "    #Encoding names\n",
    "    team_encoder = LabelEncoder().fit(Teams)\n",
    "    \n",
    "    H_encoded = team_encoder.transform(H_team)\n",
    "    A_encoded = team_encoder.transform(A_team)\n",
    " \n",
    "    #--------------------------------------\n",
    "    #Creating X feature encoded values\n",
    "    H = np.expand_dims(H_encoded, axis = -1)\n",
    "    A = np.expand_dims(A_encoded, axis = -1)\n",
    "    \n",
    "    X = np.concatenate([H, A], axis = 1)\n",
    "    \n",
    "    #--------------------------------------\n",
    "    #Scale values\n",
    "    X = StandardScaler().fit(X).transform(X)\n",
    "    return X  \n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def preprocessing(data):\n",
    "    \n",
    "    #Removing unwanted columns:\n",
    "    \n",
    "    #Extracting encoded features\n",
    "    X = \n",
    "    \n",
    "    #Extracting 'Outcome' and converting to the numpy array\n",
    "    y = \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = preprocessing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a363c3b9",
   "metadata": {},
   "source": [
    "As we have our feature, we can split the data into the train and test sets. Feel free to chose the exact method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split X and y into train and test datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e601a52",
   "metadata": {},
   "source": [
    "Finally, we can build and train out logistic regression model. Feel free to do it from scratch or using Scikit-learn (you should have the code from the previous notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e30cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and train logistic regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ec2a5",
   "metadata": {},
   "source": [
    "#### Prepare submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd32117",
   "metadata": {},
   "source": [
    "As we now have our trained model, we can pass the ```test.csv``` data file to generate our predictions and convert them to an appropriate submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify your test file path\n",
    "test_path = \n",
    "test_data = pd.read_csv(test_path)\n",
    "\n",
    "#Encoding and preprocessing our test features (do not change this part)\n",
    "X = encoder(test_data)\n",
    "\n",
    "#Making prediction\n",
    "y = \n",
    "\n",
    "#Extracting id values from the test dataset and convert them to array\n",
    "idx = \n",
    "\n",
    "#Converting to DataFrame (do not change this part)\n",
    "sub_file = pd.DataFrame([idx, y]).T\n",
    "sub_file.columns = ['id', 'outcome']\n",
    "\n",
    "#Specify your submission file\n",
    "saving_path = \n",
    "\n",
    "#Saving submission file (do not change this part)\n",
    "sub_file.to_csv(saving_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
